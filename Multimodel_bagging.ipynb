{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "def generate_features(df):\n",
    "    features = ['seconds_in_bucket', 'imbalance_buy_sell_flag',\n",
    "               'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n",
    "                'reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap',\n",
    "                'imb_s1', 'imb_s2'\n",
    "               ]\n",
    "    \n",
    "    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n",
    "    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n",
    "    \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    for i,a in enumerate(prices):\n",
    "        for j,b in enumerate(prices):\n",
    "            if i>j:\n",
    "                df[f'{a}_{b}_imb'] = df.eval(f'({a}-{b})/({a}+{b})')\n",
    "                features.append(f'{a}_{b}_imb')    \n",
    "                    \n",
    "    for i,a in enumerate(prices):\n",
    "        for j,b in enumerate(prices):\n",
    "            for k,c in enumerate(prices):\n",
    "                if i>j and j>k:\n",
    "                    max_ = df[[a,b,c]].max(axis=1)\n",
    "                    min_ = df[[a,b,c]].min(axis=1)\n",
    "                    mid_ = df[[a,b,c]].sum(axis=1)-min_-max_\n",
    "\n",
    "                    df[f'{a}_{b}_{c}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "                    features.append(f'{a}_{b}_{c}_imb2')\n",
    "    \n",
    "    return df[features]\n",
    "\n",
    "TRAINING = False\n",
    "if TRAINING:\n",
    "    df_train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n",
    "    df_ = generate_features(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "import xgboost as xgb \n",
    "import catboost as cbt \n",
    "import numpy as np \n",
    "import joblib \n",
    "import os \n",
    "\n",
    "os.system('mkdir models')\n",
    "\n",
    "model_path ='/kaggle/input/optiverbaselinezyz'\n",
    "\n",
    "N_fold = 5\n",
    "\n",
    "if TRAINING:\n",
    "    X = df_.values\n",
    "    Y = df_train['target'].values\n",
    "\n",
    "    X = X[np.isfinite(Y)]\n",
    "    Y = Y[np.isfinite(Y)]\n",
    "\n",
    "    index = np.arange(len(X))\n",
    "\n",
    "models = []\n",
    "\n",
    "def train(model_dict, modelname='lgb'):\n",
    "    if TRAINING:\n",
    "        model = model_dict[modelname]\n",
    "        model.fit(X[index%N_fold!=i], Y[index%N_fold!=i], \n",
    "                    eval_set=[(X[index%N_fold==i], Y[index%N_fold==i])], \n",
    "                    verbose=10, \n",
    "                    early_stopping_rounds=100\n",
    "                    )\n",
    "        models.append(model)\n",
    "        joblib.dump(model, './models/{modelname}_{i}.model')\n",
    "    else:\n",
    "        models.append(joblib.load(f'{model_path}/{modelname}_{i}.model'))\n",
    "    return \n",
    "\n",
    "model_dict = {\n",
    "    'lgb': lgb.LGBMRegressor(objective='regression_l1', n_estimators=500),\n",
    "    'xgb': xgb.XGBRegressor(tree_method='hist', objective='reg:absoluteerror', n_estimators=500),\n",
    "    'cbt': cbt.CatBoostRegressor(objective='MAE', iterations=3000),\n",
    "\n",
    "}\n",
    "\n",
    "for i in range(N_fold):\n",
    "    train(model_dict, 'lgb')\n",
    "#     train(model_dict, 'xgb')\n",
    "    train(model_dict, 'cbt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    feat = generate_features(test)\n",
    "    \n",
    "    sample_prediction['target'] = np.mean([model.predict(feat) for model in models], 0)\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
